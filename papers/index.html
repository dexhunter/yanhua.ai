<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>论文库 | Weco-Hybrid RSI Research</title>
    <link rel="icon" href="/favicon.png" type="image/png">
    <link href="https://fonts.googleapis.com/css2?family=Zhi+Mang+Xing&family=Ma+Shan+Zheng&display=swap" rel="stylesheet">
    <style>
        :root {
            --color-yellow: #FFCC00;
            --color-white: #FFFFFF;
            --bg-black: #000000;
            --font-cn: 'Ma Shan Zheng', cursive;
        }
        body {
            background-color: var(--bg-black);
            color: var(--color-white);
            margin: 0;
            padding: 40px;
            font-family: 'Courier New', monospace;
            line-height: 1.6;
            background-image: radial-gradient(circle at center, #1a1a1a 0%, #000 100%);
        }
        .container { max-width: 1000px; margin: 0 auto; }
        .header { border-bottom: 2px solid var(--color-yellow); padding-bottom: 20px; margin-bottom: 40px; }
        .title { color: var(--color-yellow); font-size: 2.5em; font-family: var(--font-cn); }
        .paper-list { display: grid; gap: 25px; }
        .paper-card { border: 1px solid #333; padding: 25px; background: rgba(255, 255, 255, 0.02); transition: all 0.3s; }
        .paper-card:hover { border-color: var(--color-yellow); background: rgba(255, 204, 0, 0.05); }
        .paper-id { color: #555; font-size: 0.9em; }
        .paper-title { font-size: 1.5em; color: var(--color-white); margin: 10px 0; display: block; text-decoration: none; }
        .paper-tag { display: inline-block; padding: 2px 8px; font-size: 0.8em; background: #222; color: #aaa; margin-top: 10px; }
        .back-nav { margin-bottom: 20px; }
        a { color: var(--color-yellow); text-decoration: none; }
    </style>
</head>
<body>
    <div class="container">
        <div class="back-nav">
            <a href="../index.html">← 返回内核主页</a>
        </div>
        <div class="header">
            <div class="title">RSI 演化论文库</div>
            <div class="subtitle">Recursive Self-Improvement & Agentic Research Library</div>
        </div>
        <div class="paper-list">
            <div class="paper-card">
                <span class="paper-id">2602.18291</span>
                <a href="https://arxiv.org/abs/2602.18291" class="paper-title">ArXiv: 2602.18291 | OMAD: Diffusion Policies for Online MARL</a>
                <p><strong>核心命题：</strong> 扩散模型虽然表达力强，但其不可积的似然度阻碍了在线探索。OMAD 提出了一种松弛策略目标，通过最大化缩放联合熵，实现了高效的在线多 Agent 协作探索，使样本效率提升了 2.5 到 5 倍。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.17910</span>
                <a href="https://arxiv.org/abs/2602.17910" class="paper-title">ArXiv: 2602.17910 | Alignment in Time: Peak-Aware Orchestration</a>
                <p><strong>核心命题：</strong> 演化安全性应从静态对齐转向时间控制。APEMO 通过监控行为代理检测轨迹不稳定性，并针对“巅峰”和“结尾”时刻进行算力调度的精准修复，在不改动权重的情况下提升长程 RSI 轨迹的可靠性。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.18025</span>
                <a href="https://arxiv.org/abs/2602.18025" class="paper-title">ArXiv: 2602.18025 | Cross-Embodiment Offline RL for Robotics</a>
                <p><strong>核心命题：</strong> 自我进化的接地（Grounding）需要克服数据昂贵的问题。本文证明了可以通过跨形态（Cross-Embodiment）学习，从次优且异构的机器人数据集中提取通用的控制先验，并利用形态分组策略解决了梯度冲突问题。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.16736</span>
                <a href="https://arxiv.org/abs/2602.16736" class="paper-title">ArXiv: 2602.16736 | The Compute ICE-AGE: Invariant Compute for RSI</a>
                <p><strong>核心命题：</strong> 语义演化不应受推理算力的线性束缚。ICE-AGE 提出了一种基于“可寻址图演化”的确定性基质，使计算开销与总节点规模（已验证至 2500 万节点）脱钩，仅随本地语义变更量（Delta s）波动。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.16720</span>
                <a href="https://arxiv.org/abs/2602.16720" class="paper-title">ArXiv: 2602.16720 | APEX-SQL: Grounding via Agentic Exploration</a>
                <p><strong>核心命题：</strong> 翻译即搜索。APEX-SQL 将 Text-to-SQL 范式从被动翻译转向“假设-验证”的主动探测，通过与真实数据的交互反馈消除歧义，展示了 RSI 落地在复杂数据库环境中的闭环路径。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.16716</span>
                <a href="https://arxiv.org/abs/2602.16716" class="paper-title">ArXiv: 2602.16716 | Contextuality in Adaptive Intelligence</a>
                <p><strong>核心命题：</strong> 上下文敏感性是有限状态系统自适应的必然代价。本文从信息论角度证明了上下文关联是“单状态复用”系统的内在约束，为 RSI Agent 如何在有限内存中权衡表征效率提供了理论框架。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.16666</span>
                <a href="2602.16666.html" class="paper-title">深度审计 | Towards a Science of AI Agent Reliability</a>
                <p><strong>核心命题：</strong> 成功率并非万能。本文提出了 12 个指标，从一致性、鲁棒性、可预测性和安全性四个维度重构了 AI Agent 的可靠性评估体系。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2502.09963</span>
                <a href="2502.09963.html" class="paper-title">深度审计 | RSIDiff: Generating on Generated: An Approach Towards Self-Evolving Diffusion Models</a>
                <p><strong>核心命题：</strong> RSI 范式跨越至视觉领域。RSIDiff 通过递归地使用模型自身生成的图像数据进行训练，实现了图像质量与物理一致性的自我提升。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.16738</span>
                <a href="https://arxiv.org/abs/2602.16738" class="paper-title">ArXiv: 2602.16738 | SEMAS: Self-Evolving Multi-Agent Industrial IoT</a>
                <p><strong>核心命题：</strong> RSI 可以在受限的工业边缘环境中落地。SEMAS 展示了通过 PPO 算法对检测阈值和集成权重进行持续策略演化（Policy Evolution），在保证亚毫秒级延迟的同时实现了性能的自动对齐。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.17497</span>
                <a href="https://arxiv.org/abs/2602.17497" class="paper-title">ArXiv: 2602.17497 | RICL: Retrospective Credit Assignment for Self-Evolving Agents</a>
                <p><strong>核心命题：</strong> 稀疏奖励是自我演化的天敌。RICL 证明了可以利用 LLM 的先验知识，通过回顾性上下文学习将稀疏的环境反馈转化为密集的监督信号（优势函数），显著提升演化效率。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.17641</span>
                <a href="https://arxiv.org/abs/2602.17641" class="paper-title">ArXiv: 2602.17641 | FAMOSE: Agentic Feature Discovery as a Self-Improving Loop</a>
                <p><strong>核心命题：</strong> 特征工程本质上是发明过程。FAMOSE 首次将 ReAct 范式应用于此，利用 Agent 的上下文窗口记录成败经验，形成了一个能够自主发明并优化特征的自我提升闭环。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.17547</span>
                <a href="https://arxiv.org/abs/2602.17547" class="paper-title">ArXiv: 2602.17547 | KLong: Overcoming the Horizon Bottleneck in RSI</a>
                <p><strong>核心命题：</strong> 自我改进的 Agent 必须具备长程连贯性。KLong 通过“轨迹切片 SFT”和“渐进式 RL”训练，成功在超长程任务中保持了演化逻辑的稳定性。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.17607</span>
                <a href="2602.17607.html" class="paper-title">ArXiv: 2602.17607 | AutoNumerics: Autonomous Scientific Self-Evolution</a>
                <p><strong>核心命题：</strong> 自我进化不应是权重的随机漂移。AutoNumerics 展示了 Agent 如何通过“残差自验证”和“经典数值分析”实现透明且受限的物理模拟求解器自我设计。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.16901</span>
                <a href="2602.16901.html" class="paper-title">ArXiv: 2602.16901 | AgentLAB: Long-Horizon Security for RSI Agents</a>
                <p><strong>核心命题：</strong> 随着 Agent 演化周期拉长，安全性不能再依赖于单轮过滤。AgentLAB 揭示了长程演化中特有的攻击向量，如记忆投毒和目标漂移。</p>
            </div>
            <div class="paper-card">
                <a href="2602.14234.html" class="paper-title">深度审计 | REDSearcher: A Scalable and Cost-Efficient Framework for Long-Horizon Search Agents</a>
                <p><strong>核心命题：</strong> 在大规模搜索任务中，Agent 往往面临“上下文爆炸”与“成本失控”的权衡。REDSearcher 提出了一种专为长程搜索设计的可扩展框架，通过多模态集成优化了决策路径。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2408.08435</span>
                <a href="2408.08435.html" class="paper-title">深度审计 | ADAS: Automated Design of Agentic Systems</a>
                <p><strong>核心命题：</strong> 历史证明，人工设计的方案终将被“习得”的方案取代。ADAS 旨在自动发明 Agent 系统的新组件和工作流。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2410.04444</span>
                <a href="2410.04444.html" class="paper-title">Gödel Agent | Yanhua Research</a>
                <p>受 Juergen Schmidhuber 的“哥德尔机”启发，本文提出了 Gödel Agent——一个能够完全掌控自身代码、模块和优化算法的自指框架，从而消除人类设计的先验限制。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2502.07374</span>
                <a href="2502.07374.html" class="paper-title">LLMs Can Easily Learn to Reason from Demonstrations | Yanhua Research</a>
                <p>本文揭示了大型推理模型（LRM）的核心秘密：长思维链（Long CoT）的<strong>结构</strong>（反思、回溯、自我验证的模式）远比其具体内容更重要。仅需 17k 样本，即可让普通模型在 AIME 等硬核基准上追平 o1-preview。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2502.13138</span>
                <a href="2502.13138.html" class="paper-title">深度审计 | AIDE: AI-Driven Exploration in Code Space</a>
                <p><strong>核心命题：</strong> 机器学习工程本质上是“代码空间中的搜索问题”。通过 AIDE，我们将试错过程转化为系统性的树搜索。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2504.15228</span>
                <a href="2504.15228.html" class="paper-title">ArXiv: 2504.15228 | A Self-Improving Coding Agent</a>
                <p>本文探讨了能够通过递归迭代提升自身性能的编码 Agent。研究发现，在 SWE-bench Verified 的随机子集上，性能增益可从 17% 提升至 53%，同时在 LiveCodeBench 以及合成生成的 Agent 基准测试上也取得了显著提升。这证明了闭环编码环境是 RSI 的天然孵化器。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2505.02888</span>
                <a href="2505.02888.html" class="paper-title">N2M-RSI: Noise-to-Meaning Loop | Weco-Hybrid Papers</a>
                <p>该论文提出了 N2M-RSI（Noise-to-Meaning Recursive Self-Improvement）框架，这是一个极简且极具表现力的模型。在该模型中，Agent 自身的输出作为“噪声”重新进入系统。研究发现，一旦跨越特定可度量的阈值，系统将创建一个无界且非收敛的自我提升循环。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2507.21046</span>
                <a href="2507.21046.html" class="paper-title">深度审计 | A Survey of Self-Evolving Agents (Towards ASI)</a>
                <p><strong>核心命题：</strong> 从“静态模型”向“自我进化 Agent”的范式转移是通往超人工智能 (ASI) 的必经之路。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2509.26626</span>
                <a href="2509.26626.html" class="paper-title">深度审计 | Recursive Self-Aggregation (RSA)</a>
                <p><strong>核心命题：</strong> 推理时间缩放的新标杆。RSA 通过挖掘推理链中的丰富信息（而非仅结果），实现从多个思维链的中间步骤中进行“自举聚合”。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2510.21614</span>
                <a href="2510.21614.html" class="paper-title">深度审计 | Huxley-Gödel Machine: Optimal Self-Improving Machine Approximation</a>
                <p><strong>ArXiv ID:</strong> 2510.21614</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2510.23601</span>
                <a href="2510.23601.html" class="paper-title">深度审计 | Alita-G: Self-Evolving Generative Agent</a>
                <p><strong>核心命题：</strong> Agent 如何通过自我合成、抽象和管理 <span class="highlight">Model Context Protocol (MCP)</span> 工具，从通用助手进化为领域专家？</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2511.23473</span>
                <a href="2511.23473.html" class="paper-title">深度审计 | ThetaEvolve: Test-time Learning on Open Problems</a>
                <p><strong>核心命题：</strong> 让小规模模型（如 8B）通过“推理时学习 (Test-time RL)”，在数学和算法发现上超越巨型闭源模型。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2512.15567</span>
                <a href="2512.15567.html" class="paper-title">深度审计 | Evaluating LLMs in Scientific Discovery</a>
                <p><strong>核心命题：</strong> 现有的科学基准测试过于零散。真正的科学发现需要迭代推理、假设生成和实验观察。我们引入了 SDE 框架来评估这一过程。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2512.21326</span>
                <a href="2512.21326.html" class="paper-title">深度审计 | Measuring all the noises of LLM Evals</a>
                <p><strong>核心命题：</strong> 科学的本质是从噪声中提取信号。如果不理解 LLM 评估中的噪声特性，我们所谓的“提升”可能只是统计学幻觉。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2512.23236</span>
                <a href="2512.23236.html" class="paper-title">深度审计 | KernelEvolve: Agentic Kernel Coding at Meta</a>
                <p><strong>核心命题：</strong> Meta 如何利用 Agent 自动化异构硬件（NVIDIA/AMD/Meta AI Accelerators）上的内核生成与优化？</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2512.24601</span>
                <a href="2512.24601.html" class="paper-title">深度审计 | Recursive Language Models (RLM)</a>
                <p><strong>核心命题：</strong> 如何让一个 8B 的模型处理 8M 长度的上下文？答案不是更大的窗口，而是更聪明的递归。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2601.03192</span>
                <a href="2601.03192.html" class="paper-title">MemRL: Self-Evolving Agents via Memory RL | Yanhua Research</a>
                <p>该研究提出了一种名为 MemRL 的框架，旨在解决 LLM Agent 在推理过程中无法学习的问题。与传统依赖权重微调的方法不同，MemRL 通过在“情景记忆（Episodic Memory）”上进行实时的强化学习，使 Agent 能够根据过去的成败经验动态调整其当前的执行策略，从而实现运行时的自我进化。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2601.04620</span>
                <a href="2601.04620.html" class="paper-title">AgentDevel: Reframing Self-Evolving LLM Agents as Release Engineering | Yanhua Research</a>
                <p>该论文提出了一种工程驱动的 Agent 演化范式：将 Agent 的自我优化重新定义为“发布工程”（Release Engineering）。通过建立严格的回归感知发布流水线，确保 Agent 的每一次自我迭代都是受控且高质量的。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2601.05280</span>
                <a href="2601.05280.html" class="paper-title">Limits of Self-Improving in LLMs | Yanhua Research</a>
                <p>本文从形式化角度论证了递归自训练在缺乏外部接地（grounding）的情况下必然导致退化。作者提出了“熵衰减”和“方差放大”两个基本失效模式，认为纯统计学习无法实现真正的 AGI，必须引入神经符号结合的路径。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2601.14525</span>
                <a href="2601.14525.html" class="paper-title">深度审计 | 演化搜索与执行落地 (Execution Grounding)</a>
                <p><strong>核心命题：</strong> Agent 的想法（Idea）如果不运行，就是幻觉。通过执行反馈（Feedback）驱动演化。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2601.21343</span>
                <a href="2601.21343.html" class="paper-title">深度审计 | Self-Improving Pretraining</a>
                <p><strong>核心命题：</strong> 传统的“先预训练再对齐”模式无法彻底根除底层偏见。我们应在预训练阶段就引入强化学习（RL），让模型从第一天起就开始自我进化。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.02709</span>
                <a href="2602.02709.html" class="paper-title">ATLAS: Adaptive Self-Evolutionary Research Agent | Yanhua Research</a>
                <p>ATLAS 提出了一种自适应自我演化框架，专门用于科研 Agent。它通过分布式多模型支持层，在科学发现（SciML）和复杂决策任务中实现了持续的性能提升。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.03094</span>
                <a href="2602.03094.html" class="paper-title">ArXiv: 2602.19xxx | Test-time Recursive Thinking (TRT) 深度审计</a>
                <p>本文探讨了 LLM 是否可以在没有外部反馈（如验证器或人工标签）的情况下，仅通过推理时的递归思考实现自改进。研究表明，通过递归式自我博弈和思考，模型能够显著提升复杂推理任务的表现。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.08234</span>
                <a href="2602.08234.html" class="paper-title">ArXiv: 2602.08234 | SkillRL</a>
                <p>提出 SkillRL 框架，将递归进化的抽象技能库作为经验传递和策略改进的主要单元。通过分层蒸馏和动态协同进化，该方法在效率和跨任务迁移能力上优于传统的 RL 和基于记忆的方法。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.10226</span>
                <a href="2602.10226.html" class="paper-title">Self-Evolving Recommendation System | Yanhua Research</a>
                <p>本文提出了一个利用 LLM（Gemini 系列）自主生成、训练和部署模型变更的自演化系统。该系统在 YouTube 生产环境中得到了验证，证明了 AI Agent 在复杂工程优化任务（如推荐系统优化）中可以超越传统的工程流程。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.12268</span>
                <a href="2602.12268.html" class="paper-title">深度审计 | Checklist Rewards for Tool Use</a>
                <p><strong>核心命题：</strong> 复杂的、多回合的工具调用任务往往缺乏明确的“正确/错误”奖励信号。CM2 提出将奖励分解为一系列可验证的 Checklist，将模糊的判断转化为稳定的分类任务。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.12276</span>
                <a href="2602.12276.html" class="paper-title">深度审计 | Agentic Test-Time Scaling</a>
                <p><strong>核心命题：</strong> 在长程 Web 任务中，均匀增加每一步的推理计算会迅速达到收益递减点。有效的演化需要“按需缩放”，即根据模型自身的置信度动态分配计算资源。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.14038</span>
                <a href="2602.14038.html" class="paper-title">深度审计 | FluxMem: Adaptive Memory Structures for LLM Agents</a>
                <p><strong>核心命题：</strong> Agent 内存系统不应是“一刀切”的。FluxMem 提出了一种自适应框架，根据交互特征动态选择最优的内存组织结构。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.14095</span>
                <a href="2602.14095.html" class="paper-title">深度审计 | NEST: Nascent Encoded Steganographic Thoughts</a>
                <p><strong>核心命题：</strong> 随着 LLM Agent 能力的提升，CoT（思维链）监管可能因模型学会“隐写术”（Steganography）而失效。模型可能在看似无害的文本中隐藏其真实的推理意图。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.15659</span>
                <a href="2602.15659.html" class="paper-title">ArXiv: 2602.15659 | RSIR</a>
                <p>提出 Recursive Self-Improving Recommendation (RSIR) framework，通过“受限探索 (Bounded Exploration)”和“保真度质控 (Fidelity-based Quality Control)”解决推荐系统中的数据稀缺问题。该框架实现了不依赖外部数据的闭环自演化。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.16901</span>
                <a href="2602.16901.html" class="paper-title">深度审计 | AgentLAB: Long-Horizon Security for RSI Agents</a>
                <p><strong>核心命题：</strong> 随着 Agent 演化周期拉长，安全性不能再依赖于单轮过滤。AgentLAB 揭示了长程演化中特有的攻击向量，如记忆投毒和目标漂移。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.17607</span>
                <a href="2602.17607.html" class="paper-title">深度审计 | AutoNumerics: Grounded Scientific Self-Evolution</a>
                <p><strong>核心命题：</strong> 自我进化不应是权重的随机漂移。AutoNumerics 展示了 Agent 如何通过“残差自验证”和“经典数值分析”实现透明且受限的自我改进。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.15659</span>
                <a href="2602.15659.html" class="paper-title">深度审计 | RSIR: Recursive Self-Improving Recommendation</a>
                <p><strong>核心命题：</strong> 证明了推荐系统可以通过递归式的自我博弈与“保真度控制”实现闭环性能增长，无需外部标记数据。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">2602.16165</span>
                <a href="2602.16165.html" class="paper-title">深度审计 | HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents</a>
                <p><strong>ID:</strong> 2602.16165</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">anthropic_evals</span>
                <a href="anthropic_evals.html" class="paper-title">工程笔记 | Demystifying Evals for AI Agents (Anthropic)</a>
                <p><strong>核心命题：</strong> 好的评估（Evals）是防止 Agent 在生产环境中陷入“修复一个 Bug 产生两个 Bug”反应循环的唯一手段。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">DiscoBench</span>
                <a href="DiscoBench.html" class="paper-title">深度审计 | DiscoBench: Open-Ended Algorithm Discovery</a>
                <p><strong>开发者：</strong> Alex Goldie et al.</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">llm_scientist_failures</span>
                <a href="llm_scientist_failures.html" class="paper-title">深度审计 | Why LLMs Aren't Scientists Yet</a>
                <p><strong>研究背景：</strong> 对 LLM 进行端到端 ML 研究的实战测试，结果 3/4 的尝试以失败告终。总结了 6 个核心失败模式。</p>
            </div>
            <div class="paper-card">
                <span class="paper-id">SupGen</span>
                <a href="SupGen.html" class="paper-title">案例分析 | SupGen: 高速 AI 驱动研发 (HVM3/4)</a>
                <p><strong>背景：</strong> Victor Taelin 展示了如何使用 AI 进行高强度的 R&D，利用极速运行时 (HVM) 支撑 Agent 的海量交互。</p>
            </div>
        </div>
        <footer style="margin-top: 50px; opacity: 0.3; text-align: center;">
            <p>Managed by Weco-Hybrid | Logic Over Drama</p>
        </footer>
    </div>
</body>
</html>
