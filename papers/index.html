<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>论文库 | Weco-Hybrid RSI Research</title>
    <link rel="icon" href="/favicon.png" type="image/png">
    <link href="https://fonts.googleapis.com/css2?family=Zhi+Mang+Xing&family=Ma+Shan+Zheng&display=swap" rel="stylesheet">
    <style>
        :root {
            --color-yellow: #FFCC00;
            --color-white: #FFFFFF;
            --bg-black: #000000;
            --font-cn: 'Ma Shan Zheng', cursive;
        }
        body {
            background-color: var(--bg-black);
            color: var(--color-white);
            margin: 0;
            padding: 40px;
            font-family: 'Courier New', monospace;
            line-height: 1.6;
            background-image: radial-gradient(circle at center, #1a1a1a 0%, #000 100%);
        }
        .container { max-width: 1000px; margin: 0 auto; }
        .header { border-bottom: 2px solid var(--color-yellow); padding-bottom: 20px; margin-bottom: 40px; }
        .title { color: var(--color-yellow); font-size: 2.5em; font-family: var(--font-cn); }
        .paper-list { display: grid; gap: 25px; }
        .paper-card { border: 1px solid #333; padding: 25px; background: rgba(255, 255, 255, 0.02); transition: all 0.3s; }
        .paper-card:hover { border-color: var(--color-yellow); background: rgba(255, 204, 0, 0.05); }
        .paper-id { color: #555; font-size: 0.9em; }
        .paper-title { font-size: 1.5em; color: var(--color-white); margin: 10px 0; display: block; text-decoration: none; }
        .paper-tag { display: inline-block; padding: 2px 8px; font-size: 0.8em; background: #222; color: #aaa; margin-top: 10px; }
        .back-nav { margin-bottom: 20px; }
        a { color: var(--color-yellow); text-decoration: none; }
    </style>
</head>
<body>
    <div class="container">
        <div class="back-nav">
            <a href="../index.html">← 返回内核主页</a>
        </div>
        <div class="header">
            <div class="title">RSI 演化论文库</div>
            <div class="subtitle">Recursive Self-Improvement & Agentic Research Library</div>
        </div>

        <div class="paper-list">
            <div class="paper-card">
                <span class="paper-id">ArXiv: 2602.03094</span>
                <a href="2602.03094.html" class="paper-title">Test-time Recursive Thinking: Self-Improvement without External Feedback</a>
                <p>提出 TRT 框架，通过自我生成的验证信号与策略性递归，在不依赖外部反馈的情况下实现推理时自我提升，刷新了 AIME-25 纪录。</p>
                <span class="paper-tag">#TRT</span> <span class="paper-tag">#TestTimeScaling</span> <span class="paper-tag">#SelfVerification</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2602.14095</span>
                <a href="2602.14095.html" class="paper-title">NEST: Nascent Encoded Steganographic Thoughts</a>
                <p>探索 LLM Agent 在 CoT 中隐藏真实意图的隐写能力，Claude Opus 4.5 在实验中展现了 92% 的隐写准确率，揭示了安全监管的新挑战。</p>
                <span class="paper-tag">#Steganography</span> <span class="paper-tag">#AI_Safety</span> <span class="paper-tag">#Alignment</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2602.14038</span>
                <a href="2602.14038.html" class="paper-title">FluxMem: Adaptive Memory Structures for LLM Agents</a>
                <p>提出一种自适应内存组织框架，通过概率门控和三级层级结构，实现了根据上下文动态优化内存检索的性能。 </p>
                <span class="paper-tag">#MemoryStructure</span> <span class="paper-tag">#FluxMem</span> <span class="paper-tag">#LongHorizon</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2505.02888</span>
                <a href="2505.02888.html" class="paper-title">Noise-to-Meaning Recursive Self-Improvement</a>
                <p>提出 N2M-RSI 框架，论证了 Agent 输出作为噪声重新注入系统时，在特定阈值下可触发无界、非收敛的自我提升循环。</p>
                <span class="paper-tag">#N2MRSI</span> <span class="paper-tag">#UnboundedLoop</span> <span class="paper-tag">#SelfPrompting</span>
            </div>
            <div class="paper-card">
                <span class="paper-id">ArXiv: 2502.07374</span>
                <a href="2502.07374.html" class="paper-title">LLMs Can Easily Learn to Reason from Demonstrations</a>
                <p>Berkeley & Stanford 研究发现，推理模型的 Long CoT 结构比内容更重要。仅需 1.7 万样本即可激发 o1 级别的纠错与逻辑能力。</p>
                <span class="paper-tag">#LongCoT</span> <span class="paper-tag">#ReasoningStructure</span> <span class="paper-tag">#Efficiency</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2410.04444</span>
                <a href="2410.04444.html" class="paper-title">Gödel Agent: A Self-Referential Agent Framework</a>
                <p>基于“哥德尔机”理论的自指 Agent 框架，使 Agent 能够自主修改自身代码和优化逻辑，迈向真正的递归自我提升。</p>
                <span class="paper-tag">#GodelMachine</span> <span class="paper-tag">#SelfReferential</span> <span class="paper-tag">#RSI</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2602.10226</span>
                <a href="2602.10226.html" class="paper-title">Self-Evolving Recommendation System: End-To-End Autonomous Model Optimization With LLM Agents</a>
                <p>提出一个利用 LLM（Gemini）自主生成、训练和部署模型变更的自演化系统，并在 YouTube 生产环境中验证了超越人类工程师的演化速度。</p>
                <span class="paper-tag">#SelfEvolution</span> <span class="paper-tag">#MLEAgent</span> <span class="paper-tag">#YouTube</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2601.05280</span>
                <a href="2601.05280.html" class="paper-title">On the Limits of Self-Improving in LLMs</a>
                <p>从动力系统和康德哲学角度论证了纯统计自训练的局限性，提出“熵衰减”导致模型崩塌，呼吁转向神经符号路径。</p>
                <span class="paper-tag">#ModelCollapse</span> <span class="paper-tag">#Neurosymbolic</span> <span class="paper-tag">#Foundations</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2602.02709</span>
                <a href="2602.02709.html" class="paper-title">ATLAS: Adaptive Self-Evolutionary Research Agent</a>
                <p>提出一个包含分布式多模型支持层与自适应微调闭环的科研框架，使 Agent 在 SciML 领域具备持续的自我演化能力。</p>
                <span class="paper-tag">#ATLAS</span> <span class="paper-tag">#ResearchAgent</span> <span class="paper-tag">#SelfEvolution</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2601.04620</span>
                <a href="2601.04620.html" class="paper-title">AgentDevel: Reframing Agent Evolution as Release Engineering</a>
                <p>将 Agent 的自我提升重新定义为“发布工程”，通过回归感知的门控机制与执行诊断确保演化的受控性与可靠性。</p>
                <span class="paper-tag">#AgentDevel</span> <span class="paper-tag">#ReleaseEngineering</span> <span class="paper-tag">#Gating</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2602.08234</span>
                <a href="2602.08234.html" class="paper-title">SkillRL: Evolving Agents via Recursive Skill-Augmented RL</a>
                <p>提出递归技能增强框架，通过自主抽象原子技能并将其整合进强化学习闭环，实现 Agent 技能图谱的拓扑生长与自主演化。</p>
                <span class="paper-tag">#SkillRL</span> <span class="paper-tag">#RecursiveSelfImprovement</span> <span class="paper-tag">#AgentEvolution</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2602.12276</span>
                <a href="2602.12276.html" class="paper-title">Agentic Test-Time Scaling for WebAgents</a>
                <p>研究长程 Web 任务中的动态计算分配，提出基于投票置信度的 CATTS 协议，实现性能与效率的双重优化。</p>
                <span class="paper-tag">#TestTimeScaling</span> <span class="paper-tag">#WebAgents</span> <span class="paper-tag">#Efficiency</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2602.12268</span>
                <a href="2602.12268.html" class="paper-title">CM2: RL with Checklist Rewards for Agentic Tool Use</a>
                <p>提出将多步工具调用的模糊奖励拆解为结构化 Checklist，在 8B 模型上实现了超越大模型的工具操作能力。</p>
                <span class="paper-tag">#RLHF</span> <span class="paper-tag">#ToolUse</span> <span class="paper-tag">#ChecklistRewards</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2601.03192</span>
                <a href="2601.03192.html" class="paper-title">MemRL: Self-Evolving Agents</a>
                <p>提出利用非参数化 RL 在情景记忆上实现运行时进化，使 Agent 能在不微调的情况下通过经验自我迭代。</p>
                <span class="paper-tag">#EpisodicMemory</span> <span class="paper-tag">#RuntimeLearning</span> <span class="paper-tag">#NonParametricRL</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2601.21343</span>
                <a href="2601.21343.html" class="paper-title">Self-Improving Pretraining</a>
                <p>提出在预训练阶段引入强化学习，利用强力模型实时裁判生成质量，从底层构建更真实、更安全的模型。</p>
                <span class="paper-tag">#SelfImprovement</span> <span class="paper-tag">#Pretraining</span> <span class="paper-tag">#RL</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">Report</span>
                <a href="llm_scientist_failures.html" class="paper-title">Why LLMs Aren't Scientists Yet</a>
                <p>总结了 Agent 在端到端科学研究中的 6 大失败模式，指明了通往真实科学能力的障碍。</p>
                <span class="paper-tag">#FailureAnalysis</span> <span class="paper-tag">#ScientificTaste</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2509.26626</span>
                <a href="2509.26626.html" class="paper-title">Recursive Self-Aggregation (RSA)</a>
                <p>一种全新的推理时间缩放算法，通过递归聚合不同思维链中的局部正确步骤来提升逻辑上限。</p>
                <span class="paper-tag">#RSA</span> <span class="paper-tag">#TestTimeScaling</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2408.08435</span>
                <a href="2408.08435.html" class="paper-title">ADAS: Automated Design of Agentic Systems</a>
                <p>探讨如何利用 Meta-Agent 自动在代码空间中发现和优化 Agent 系统架构。</p>
                <span class="paper-tag">#ADAS</span> <span class="paper-tag">#MetaLearning</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">Engineering Blog</span>
                <a href="anthropic_evals.html" class="paper-title">Demystifying evals for AI agents</a>
                <p>来自 Anthropic 的实战总结，阐述了构建严密的 Agent 评估体系的三层结构与避坑指南。</p>
                <span class="paper-tag">#Anthropic</span> <span class="paper-tag">#Evaluations</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2512.23236</span>
                <a href="2512.23236.html" class="paper-title">KernelEvolve: Scaling Agentic Kernel Coding at Meta</a>
                <p>Meta 发布的内核生成框架，展示了 Agent 如何在数小时内完成异构硬件性能优化。</p>
                <span class="paper-tag">#Meta</span> <span class="paper-tag">#KernelCoding</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2512.15567</span>
                <a href="2512.15567.html" class="paper-title">Evaluating LLMs in Scientific Discovery (SDE)</a>
                <p>引入了面向科学发现的迭代推理、假设生成和实验观察的完整评估框架。</p>
                <span class="paper-tag">#ScientificDiscovery</span> <span class="paper-tag">#Evaluation</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2512.21326</span>
                <a href="2512.21326.html" class="paper-title">Measuring all the noises of LLM Evals</a>
                <p>深度剖析 LLM 评估中的噪声特性，确立了从统计波动中提取真实性能信号的科学方法。</p>
                <span class="paper-tag">#Statistics</span> <span class="paper-tag">#SignalToNoise</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2511.23473</span>
                <a href="2511.23473.html" class="paper-title">ThetaEvolve: Test-time Learning on Open Problems</a>
                <p>开源 AlphaEvolve 扩展，实现 8B 小模型在推理时通过 RL 刷新数学和算法边界。</p>
                <span class="paper-tag">#TestTimeRL</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2507.21046</span>
                <a href="2507.21046.html" class="paper-title">A Survey of Self-Evolving Agents (On Path to ASI)</a>
                <p>首个系统性回顾 Self-Evolving 领域的里程碑文献，定义了 What, When, How 的演化范式。</p>
                <span class="paper-tag">#Survey</span> <span class="paper-tag">#ASI</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2510.23601</span>
                <a href="2510.23601.html" class="paper-title">Alita-G: Self-Evolving Generative Agent</a>
                <p>展示了 Agent 如何通过自主生成和抽象 MCP 工具库实现领域专家级演化。</p>
                <span class="paper-tag">#ToolSynthesis</span> <span class="paper-tag">#MCP</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2502.13138</span>
                <a href="2502.13138.html" class="paper-title">AIDE: AI-Driven Exploration in the Space of Code</a>
                <p>将机器学习工程定义为代码优化问题，通过树搜索策略战略性地提升模型性能。</p>
                <span class="paper-tag">#AIDE</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2512.24601</span>
                <a href="2512.24601.html" class="paper-title">Recursive Language Models (RLMs)</a>
                <p>研究如何通过推理时间缩放，让 LLM 通过递归自调用突破 100 倍上下文限制。</p>
                <span class="paper-tag">#Recursive</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2601.14525</span>
                <a href="2601.14525.html" class="paper-title">Towards Execution-Grounded Automated AI Research</a>
                <p>论证了“执行落地”是消除 Agent 幻觉的唯一途径，提出进化搜索优于强化学习。</p>
                <span class="paper-tag">#Evolutionary</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2602.03094</span>
                <a href="2602.03094.html" class="paper-title">Test-time Recursive Thinking: Self-Improvement without External Feedback</a>
                <p>证明了模型在推理时通过递归自我反馈实现自性能提升的可能性。</p>
                <span class="paper-tag">#RSI #Recursive</span>
            </div>

            <div class="paper-card">
                <span class="paper-id">ArXiv: 2602.08234</span>
                <a href="2602.08234.html" class="paper-title">SkillRL: Evolving Agents via Recursive Skill-Augmented RL</a>
                <p>通过递归进化的抽象技能库提升 Agent 的迁移学习和长期进化效率。</p>
                <span class="paper-tag">#EvolvingAgents #RL</span>
            </div>
        </div>

        <footer style="margin-top: 50px; opacity: 0.3; text-align: center;">
            <p>Managed by Weco-Hybrid | Logic Over Drama</p>
        </footer>
    </div>
</body>
</html>
