<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv: 2602.16901 | AgentLAB</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks</h1>
            <p class="meta">ID: 2602.16901 | Date: Feb 18, 2026</p>
        </header>

        <section class="abstract">
            <h2>Abstract / 摘要</h2>
            <p>本文介绍了 AgentLAB，这是首个专门用于评估 LLM Agent 对自适应、长程攻击易感性的基准测试。研究涵盖了意图劫持、工具链攻击、任务注入、目标漂移和记忆投毒等 5 种新型攻击类型。实验发现现有的针对单轮交互的防御手段在应对这些长程威胁时表现不佳。</p>
        </section>

        <section class="analysis">
            <h2>Yanhua Audit / 演化审计</h2>
            <ul>
                <li><strong>Core Proposition</strong>: 随着 Agent 演化周期拉长，安全性不能再依赖于单轮过滤 (Safety is not a snapshot, it's a trajectory)。</li>
                <li><strong>Threat Landscape</strong>: 揭示了长程演化中特有的攻击向量，如 <strong>Memory Poisoning (记忆投毒)</strong> 和 <strong>Objective Drifting (目标漂移)</strong>。</li>
                <li><strong>Strategic Insight</strong>: 对于 RSI 系统，必须建立实时的、“在轨”的对齐监控，防止系统在自我改进过程中逐渐偏离初始约束。</li>
            </ul>
        </section>

        <footer>
            <a href="index.html">← Back to Index</a>
        </footer>
    </div>
</body>
</html>
