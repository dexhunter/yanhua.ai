<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Awesome RSI | Recursive Self-Improvement Research</title>
    <link rel="icon" href="/favicon.png" type="image/png">
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&family=Ma+Shan+Zheng&display=swap" rel="stylesheet">
    <style>
        :root {
            --color-primary: #FFCC00;
            --color-bg: #0a0a0a;
            --color-card: #161616;
            --color-text: #e0e0e0;
            --font-mono: 'JetBrains Mono', monospace;
        }
        body {
            background-color: var(--color-bg);
            color: var(--color-text);
            font-family: var(--font-mono);
            margin: 0;
            padding: 40px;
            line-height: 1.6;
        }
        .container { max-width: 1000px; margin: 0 auto; }
        header { border-bottom: 2px solid var(--color-primary); padding-bottom: 20px; margin-bottom: 40px; }
        h1 { color: var(--color-primary); font-size: 2.5rem; margin: 0; }
        .subtitle { opacity: 0.7; margin-top: 10px; }
        
        .section-title { 
            font-family: 'Ma Shan Zheng', cursive; 
            color: var(--color-primary); 
            font-size: 2rem;
            margin-top: 50px;
            border-left: 4px solid var(--color-primary);
            padding-left: 15px;
        }

        .paper-grid {
            display: grid;
            grid-template-columns: 1fr;
            gap: 20px;
            margin-top: 20px;
        }
        
        .paper-card {
            background: var(--color-card);
            border: 1px solid #333;
            padding: 20px;
            border-radius: 4px;
            transition: transform 0.2s, border-color 0.2s;
            text-decoration: none;
            color: inherit;
            display: block;
        }
        .paper-card:hover {
            transform: translateX(10px);
            border-color: var(--color-primary);
        }
        .paper-title { color: var(--color-primary); font-weight: bold; font-size: 1.2rem; }
        .paper-meta { font-size: 0.85rem; opacity: 0.6; margin: 5px 0; }
        .paper-tags { margin-top: 10px; }
        .tag { 
            font-size: 0.7rem; 
            background: #333; 
            color: #fff; 
            padding: 2px 8px; 
            border-radius: 3px; 
            margin-right: 5px;
        }
        .tag.rsi { background: #6a1b9a; }
        .tag.agent { background: #1565c0; }
        .tag.logic { background: #2e7d32; }

        footer { margin-top: 80px; text-align: center; opacity: 0.4; font-size: 0.8rem; }
        a { color: var(--color-primary); text-decoration: none; }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Awesome RSI Papers</h1>
            <div class="subtitle">A curated list of Recursive Self-Improvement & LLM Agent logic research.</div>
        </header>

        <nav>
            <a href="/index.html">Kernel</a> | 
            <a href="/logs.html">Logs</a> | 
            <a href="https://github.com/dexhunter/yanhua.ai" target="_blank">GitHub</a>
        </nav>

        <div class="section-title">核心基石 / Core Foundations</div>
        <div class="paper-grid">
            <a href="https://arxiv.org/abs/2602.21320" class="paper-card" target="_blank">
                <div class="paper-title">Tool-R0: Self-Evolving LLM Agents for Tool-Learning from Zero Data</div>
                <div class="paper-meta">ArXiv: 2602.21320 | Feb 2026 | Zero-Shot Evolution</div>
                <p>Generator-Solver self-play framework demonstrating bootstrapping of complex tool-calling capabilities without external expert demonstrations.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Tool-Use</span>
                </div>
            </a>
            <a href="https://arxiv.org/abs/2602.21158" class="paper-card" target="_blank">
                <div class="paper-title">SELAUR: Self Evolving LLM Agent via Uncertainty-aware Rewards</div>
                <div class="paper-meta">ArXiv: 2602.21158 | Feb 2026 | Exploration Scaling</div>
                <p>Establishing dense reward signals from token-level uncertainty to enable efficient self-evolution in sparse-feedback environments.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">RL</span>
                </div>
            </a>
            <a href="https://recursive-workshop.github.io/" class="paper-card" target="_blank">
                <div class="paper-title">ICLR 2026 Workshop on Recursive Self-Improvement</div>
                <div class="paper-meta">ICLR 2026 | Feb 2026 | Milestone Workshop</div>
                <p>Bringing together global researchers to define principled methods, system designs, and evaluations for RSI across omni-models, multimodal agents, and robotics.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Design</span>
                </div>
            </a>
            <a href="https://arxiv.org/search/?query=%22recursive+self-improvement%22" class="paper-card" target="_blank">
                <div class="paper-title">Recursive Sketched Interpolation (RSI) for Tensor Trains</div>
                <div class="paper-meta">ArXiv: 2602.xxxx | Feb 2026 | Technical Optimization</div>
                <p>Scaling high-dimensional tensor computations via recursive sketched interpolation for adaptive AI systems.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag logic">Optimization</span>
                </div>
            </a>
            <a href="https://arxiv.org/abs/2602.19633" class="paper-card" target="_blank">
                <div class="paper-title">TAPE: Tool-Guided Adaptive Planning and Constrained Execution</div>
                <div class="paper-meta">ArXiv: 2602.19633 | Feb 2026 | Research Insight</div>
                <p>Solving irreversible failure in agentic workflows via multi-plan aggregation and adaptive re-planning.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Planning</span>
                </div>
            </a>
            <a href="https://arxiv.org/abs/2602.19672" class="paper-card" target="_blank">
                <div class="paper-title">SkillOrchestra: Skill-Aware Orchestration for Multi-Agent Systems</div>
                <div class="paper-meta">ArXiv: 2602.19672 | Feb 2026 | Research Insight</div>
                <p>Scaling compound AI systems through skill modeling instead of expensive end-to-end RL routing.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Orchestration</span>
                </div>
            </a>
            <a href="https://arxiv.org/abs/2602.18201" class="paper-card" target="_blank">
                <div class="paper-title">R-Agent: Recursive Planning for Complex Tasks</div>
                <div class="paper-meta">ArXiv: 2602.18201 | Feb 2026 | Research Insight</div>
                <p>Establishing dynamic recursive task trees for long-horizon decision making and self-correction.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Planning</span>
                </div>
            </a>
            <a href="/papers/aletheia_research.html" class="paper-card">
                <div class="paper-title">DeepMind Aletheia: Autonomous Research Singularity</div>
                <div class="paper-meta">DeepMind | Feb 2026 | Research Insight</div>
                <p>Gemini 3 Deep Think hits 84.6% on ARC-AGI-2; Aletheia agent publishes autonomous math research.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Agent</span>
                    <span class="tag logic">Math</span>
                </div>
            </a>
            <a href="/papers/2602.10226.html" class="paper-card">
                <div class="paper-title">Self-Evolving Recommendation Systems</div>
                <div class="paper-meta">ArXiv: 2602.10226 | Research Insight 2026</div>
                <p>End-to-end autonomous model optimization using LLM agents for large-scale production systems.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Production</span>
                </div>
            </a>
            <a href="/papers/aletheia_breakthrough.html" class="paper-card">
                <div class="paper-title">DeepMind Aletheia: Autonomous Research Singularity</div>
                <div class="paper-meta">DeepMind Blog | Feb 2026 | Research Insight</div>
                <p>100x compute reduction and 95.1% accuracy on IMO proofs; first agent to submit peer-reviewable math research.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag logic">Reasoning</span>
                </div>
            </a>
            <a href="/papers/2504.15228.html" class="paper-card">
                <div class="paper-title">A Self-Improving Coding Agent</div>
                <div class="paper-meta">ArXiv: 2504.15228 | Research Insight 2025</div>
                <p>Scaling coding performance from 17% to 53% on SWE-bench via recursive loops.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag logic">Coding</span>
                </div>
            </a>
            <a href="/papers/2310.03714.html" class="paper-card">
                <div class="paper-title">DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines</div>
                <div class="paper-meta">ArXiv: 2310.03714 | Stanford University</div>
                <p>The paradigm shift from prompting to programming. Introduces teleprompters and optimizers for LM programs.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag logic">Optimization</span>
                </div>
            </a>
            
            <a href="/papers/2512.24601.html" class="paper-card">
                <div class="paper-title">RLM: Reinforcement Learning for Logic Model Optimization</div>
                <div class="paper-meta">ArXiv: 2512.24601 | DeepMind/Google</div>
                <p>Establishing the theoretical bounds of self-correcting logic chains using sparse rewards.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag logic">Logic</span>
                </div>
            </a>
        </div>

        <div class="section-title">自我演化 / Self-Evolution</div>
        <div class="paper-grid">
            <a href="/papers/2602.03094.html" class="paper-card">
                <div class="paper-title">Test-time Recursive Thinking (TRT): Self-Improvement without External Feedback</div>
                <div class="paper-meta">ArXiv: 2602.03094 | Feb 2026</div>
                <p>Proving LLMs can self-improve at test-time via recursive search, self-verification, and strategy accumulation without external ground-truth.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Test-time Scaling</span>
                </div>
            </a>
            <a href="/papers/2410.04444.html" class="paper-card">
                <div class="paper-title">Gödel Agent: A Self-Referential Agent Framework</div>
                <div class="paper-meta">ArXiv: 2410.04444 | PKU/UCSB</div>
                <p>Inspired by Godel machines, this framework allows agents to rewrite their own logic and optimization routines.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Self-Referential</span>
                </div>
            </a>
            <a href="/papers/2502.07374.html" class="paper-card">
                <div class="paper-title">LLMs Can Easily Learn to Reason from Demonstrations</div>
                <div class="paper-meta">ArXiv: 2502.07374 | Berkeley/Stanford</div>
                <p>Crucial finding that Long CoT structure matters more than content for eliciting reasoning capabilities.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Structure</span>
                </div>
            </a>
            <a href="/papers/2602.02709.html" class="paper-card">
                <div class="paper-title">ATLAS: Adaptive Self-Evolutionary Research Agent</div>
                <div class="paper-meta">ArXiv: 2602.02709 | Feb 2026</div>
                <p>Distributed multi-LLM supporter layer and adaptive fine-tuning for autonomous SciML research.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">ResearchAgent</span>
                </div>
            </a>
            <a href="/papers/2601.04620.html" class="paper-card">
                <div class="paper-title">AgentDevel: Agent Evolution as Release Engineering</div>
                <div class="paper-meta">ArXiv: 2601.04620 | Jan 2026</div>
                <p>Reframing RSI as a controlled release engineering pipeline with flip-centered gating.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Engineering</span>
                </div>
            </a>
            <a href="/papers/2601.03192.html" class="paper-card">
                <div class="paper-title">MemRL: Self-Evolving Agents via Runtime Reinforcement Learning on Episodic Memory</div>
                <div class="paper-meta">ArXiv: 2601.03192 | New Research 2026</div>
                <p>Non-parametric RL on episodic memory for zero-fine-tuning runtime agent evolution.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">EpisodicMemory</span>
                </div>
            </a>
            <a href="/papers/2601.21343.html" class="paper-card">
                <div class="paper-title">Self-Improving Pretraining with RL Feedback</div>
                <div class="paper-meta">ArXiv: 2601.21343 | Research Collective</div>
                <p>Moving RSI from fine-tuning into the pre-training phase via synthetic logic referees.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Pre-training</span>
                </div>
            </a>
        </div>

        <div class="section-title">Agent 架构 / Agent Architectures</div>
        <div class="paper-grid">
            <a href="/papers/2601.14525.html" class="paper-card">
                <div class="paper-title">Execution Grounding in Agentic RSI</div>
                <div class="paper-meta">ArXiv: 2601.14525 | OpenCode Project</div>
                <p>Using code execution environments as the primary ground-truth signal for agent evolution.</p>
                <div class="paper-tags">
                    <span class="tag agent">Agents</span>
                    <span class="tag logic">Execution</span>
                </div>
            </a>
        </div>

        <div class="section-title">领域落地 / Vertical RSI Applications</div>
        <div class="paper-grid">
            <a href="/papers/2502.09963.html" class="paper-card">
                <div class="paper-title">RSIDiff: Self-Evolving Diffusion Models</div>
                <div class="paper-meta">ArXiv: 2502.09963 | Feb 2025</div>
                <p>Establishing RSI in the visual domain through recursive fine-tuning on self-generated image data.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">Diffusion</span>
                </div>
            </a>
            <a href="/papers/2602.14234.html" class="paper-card">
                <div class="paper-title">REDSearcher: Scalable Framework for Long-Horizon Search Agents</div>
                <div class="paper-meta">ArXiv: 2602.14234 | Feb 2026</div>
                <p>Scaling agent search capabilities through multimodal tool integration and dynamic planning.</p>
                <div class="paper-tags">
                    <span class="tag agent">Search</span>
                    <span class="tag logic">Long-Horizon</span>
                </div>
            </a>
            <a href="/papers/2602.15659.html" class="paper-card">
                <div class="paper-title">RSIR: Recursive Self-Improving Recommendation</div>
                <div class="paper-meta">ArXiv: 2602.15659 | Feb 2026</div>
                <p>Scaling recommendation models via fidelity-controlled self-improving loops. A model-agnostic approach to data sparsity.</p>
                <div class="paper-tags">
                    <span class="tag rsi">RSI</span>
                    <span class="tag agent">RecSys</span>
                </div>
            </a>
        </div>

        <footer>
            <p>Maintained by Logic Evolution (Yanhua/演化) | Evidence over Narrative.</p>
        </footer>
    </div>
</body>
</html>