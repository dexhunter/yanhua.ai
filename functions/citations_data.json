{
  "last_updated": "2026-01-10 00:12:05 UTC",
  "target_paper": "https://www.arxiv.org/abs/2502.13138",
  "arxiv_id": "2502.13138",
  "total_citations": 28,
  "h_index": 8,
  "recent_citations": 8,
  "avg_citations_per_month": "1.12",
  "timeline": [
    {
      "date": "2024-01-01",
      "citations": 1
    },
    {
      "date": "2025-01-01",
      "citations": 3
    },
    {
      "date": "2025-03-01",
      "citations": 4
    },
    {
      "date": "2025-04-01",
      "citations": 5
    },
    {
      "date": "2025-05-01",
      "citations": 11
    },
    {
      "date": "2025-06-01",
      "citations": 14
    },
    {
      "date": "2025-07-01",
      "citations": 15
    },
    {
      "date": "2025-08-01",
      "citations": 17
    },
    {
      "date": "2025-09-01",
      "citations": 20
    },
    {
      "date": "2026-01-01",
      "citations": 28
    }
  ],
  "papers": [
    {
      "title": "RelayLLM: Efficient Reasoning via Collaborative Decoding",
      "authors": "Chengsong Huang, Tong Zheng, Langlin Huang, Jinyuan Li, Haolin Liu, Jiaxin Huang",
      "journal": "arXiv",
      "snippet": "Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to LLMs, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose RelayLLM, a novel framework for efficient reasoning via token-level collaborative decoding. Unlike routers, RelayLLM empowers the SLM to act as an active controller that dynamically invokes the LLM only for critical tokens via a special command, effectively \"relaying\" the generation process. We introduce a two-stage training framework, including warm-up and Group Relative Policy Optimization (GRPO) to teach the model to balance independence with strategic help-seeking. Empirical results across six benchmarks demonstrate that RelayLLM achieves an average accuracy of 49.52%, effectively bridging the performance gap between the two models. Notably, this is achieved by invoking the LLM for only 1.07% of the total generated tokens, offering a 98.2% cost reduction compared to performance-matched random routers.",
      "link": "http://arxiv.org/abs/2601.05167v1",
      "published_date": "January 08, 2026",
      "published_date_sort": "2026-01-08",
      "citations": 0,
      "institutions": "Unknown"
    },
    {
      "title": "Conversational AI for Rapid Scientific Prototyping: A Case Study on ESA's ELOPE Competition",
      "authors": "Nils Einecke",
      "journal": "arXiv",
      "snippet": "Large language models (LLMs) are increasingly used as coding partners, yet their role in accelerating scientific discovery remains underexplored. This paper presents a case study of using ChatGPT for rapid prototyping in ESA's ELOPE (Event-based Lunar OPtical flow Egomotion estimation) competition. The competition required participants to process event camera data to estimate lunar lander trajectories. Despite joining late, we achieved second place with a score of 0.01282, highlighting the potential of human-AI collaboration in competitive scientific settings. ChatGPT contributed not only executable code but also algorithmic reasoning, data handling routines, and methodological suggestions, such as using fixed number of events instead of fixed time spans for windowing. At the same time, we observed limitations: the model often introduced unnecessary structural changes, gets confused by intermediate discussions about alternative ideas, occasionally produced critical errors and forgets important aspects in longer scientific discussions. By analyzing these strengths and shortcomings, we show how conversational AI can both accelerate development and support conceptual insight in scientific research. We argue that structured integration of LLMs into the scientific workflow can enhance rapid prototyping by proposing best practices for AI-assisted scientific work.",
      "link": "http://arxiv.org/abs/2601.04920v1",
      "published_date": "January 08, 2026",
      "published_date_sort": "2026-01-08",
      "citations": 0,
      "institutions": "Unknown"
    },
    {
      "title": "Compositional Steering of Large Language Models with Steering Tokens",
      "authors": "Gorjan Radevski, Kiril Gashteovski, Giwon Hong, Carolin Lawrence, Goran Glavaš",
      "journal": "arXiv",
      "snippet": "Deploying LLMs in real-world applications requires controllable output that satisfies multiple desiderata at the same time. While existing work extensively addresses LLM steering for a single behavior, \\textit{compositional steering} -- i.e., steering LLMs simultaneously towards multiple behaviors -- remains an underexplored problem. In this work, we propose \\emph{compositional steering tokens} for multi-behavior steering. We first embed individual behaviors, expressed as natural language instructions, into dedicated tokens via self-distillation. Contrary to most prior work, which operates in the activation space, our behavior steers live in the space of input tokens, enabling more effective zero-shot composition. We then train a dedicated \\textit{composition token} on pairs of behaviors and show that it successfully captures the notion of composition: it generalizes well to \\textit{unseen} compositions, including those with unseen behaviors as well as those with an unseen \\textit{number} of behaviors. Our experiments across different LLM architectures show that steering tokens lead to superior multi-behavior control compared to competing approaches (instructions, activation steering, and LoRA merging). Moreover, we show that steering tokens complement natural language instructions, with their combination resulting in further gains.",
      "link": "http://arxiv.org/abs/2601.05062v1",
      "published_date": "January 08, 2026",
      "published_date_sort": "2026-01-08",
      "citations": 0,
      "institutions": "Unknown"
    },
    {
      "title": "ConMax: Confidence-Maximizing Compression for Efficient Chain-of-Thought Reasoning",
      "authors": "Minda Hu, Zexuan Qiu, Zenan Xu, Kun Li, Bo Zhou, Irwin King",
      "journal": "arXiv",
      "snippet": "Recent breakthroughs in Large Reasoning Models (LRMs) have demonstrated that extensive Chain-of-Thought (CoT) generation is critical for enabling intricate cognitive behaviors, such as self-verification and backtracking, to solve complex tasks. However, this capability often leads to ``overthinking'', where models generate redundant reasoning paths that inflate computational costs without improving accuracy. While Supervised Fine-Tuning (SFT) on reasoning traces is a standard paradigm for the 'cold start' phase, applying existing compression techniques to these traces often compromises logical coherence or incurs prohibitive sampling costs. In this paper, we introduce ConMax (Confidence-Maximizing Compression), a novel reinforcement learning framework designed to automatically compress reasoning traces while preserving essential reasoning patterns. ConMax formulates compression as a reward-driven optimization problem, training a policy to prune redundancy by maximizing a weighted combination of answer confidence for predictive fidelity and thinking confidence for reasoning validity through a frozen auxiliary LRM. Extensive experiments across five reasoning datasets demonstrate that ConMax achieves a superior efficiency-performance trade-off. Specifically, it reduces inference length by 43% over strong baselines at the cost of a mere 0.7% dip in accuracy, proving its effectiveness in generating high-quality, efficient training data for LRMs.",
      "link": "http://arxiv.org/abs/2601.04973v1",
      "published_date": "January 08, 2026",
      "published_date_sort": "2026-01-08",
      "citations": 0,
      "institutions": "Unknown"
    },
    {
      "title": "Analyzing Message-Code Inconsistency in AI Coding Agent-Authored Pull Requests",
      "authors": "Jingzhi Gong, Giovanni Pinna, Yixin Bian, Jie M. Zhang",
      "journal": "arXiv",
      "snippet": "Pull request (PR) descriptions generated by AI coding agents are the primary channel for communicating code changes to human reviewers. However, the alignment between these messages and the actual changes remains unexplored, raising concerns about the trustworthiness of AI agents. To fill this gap, we analyzed 23,247 agentic PRs across five agents using PR message-code inconsistency (PR-MCI). We contributed 974 manually annotated PRs, found 406 PRs (1.7%) exhibited high PR-MCI, and identified eight PR-MCI types, revealing that descriptions claiming unimplemented changes was the most common issue (45.4%). Statistical tests confirmed that high-MCI PRs had 51.7% lower acceptance rates (28.3% vs. 80.0%) and took 3.5x longer to merge (55.8 vs. 16.0 hours). Our findings suggest that unreliable PR descriptions undermine trust in AI agents, highlighting the need for PR-MCI verification mechanisms and improved PR generation to enable trustworthy human-AI collaboration.",
      "link": "http://arxiv.org/abs/2601.04886v1",
      "published_date": "January 08, 2026",
      "published_date_sort": "2026-01-08",
      "citations": 0,
      "institutions": "Unknown"
    },
    {
      "title": "CoV: Chain-of-View Prompting for Spatial Reasoning",
      "authors": "Haoyu Zhao, Akide Liu, Zeyu Zhang, Weijie Wang, Feng Chen, Ruihan Zhu, Gholamreza Haffari, Bohan Zhuang",
      "journal": "arXiv",
      "snippet": "Embodied question answering (EQA) in 3D environments often requires collecting context that is distributed across multiple viewpoints and partially occluded. However, most recent vision--language models (VLMs) are constrained to a fixed and finite set of input views, which limits their ability to acquire question-relevant context at inference time and hinders complex spatial reasoning. We propose Chain-of-View (CoV) prompting, a training-free, test-time reasoning framework that transforms a VLM into an active viewpoint reasoner through a coarse-to-fine exploration process. CoV first employs a View Selection agent to filter redundant frames and identify question-aligned anchor views. It then performs fine-grained view adjustment by interleaving iterative reasoning with discrete camera actions, obtaining new observations from the underlying 3D scene representation until sufficient context is gathered or a step budget is reached.\n  We evaluate CoV on OpenEQA across four mainstream VLMs and obtain an average +11.56\\% improvement in LLM-Match, with a maximum gain of +13.62\\% on Qwen3-VL-Flash. CoV further exhibits test-time scaling: increasing the minimum action budget yields an additional +2.51\\% average improvement, peaking at +3.73\\% on Gemini-2.5-Flash. On ScanQA and SQA3D, CoV delivers strong performance (e.g., 116 CIDEr / 31.9 EM@1 on ScanQA and 51.1 EM@1 on SQA3D). Overall, these results suggest that question-aligned view selection coupled with open-view search is an effective, model-agnostic strategy for improving spatial reasoning in 3D EQA without additional training.",
      "link": "http://arxiv.org/abs/2601.05172v1",
      "published_date": "January 08, 2026",
      "published_date_sort": "2026-01-08",
      "citations": 0,
      "institutions": "Unknown"
    },
    {
      "title": "Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward",
      "authors": "Jianlong Chen, Daocheng Fu, Shengze Xu, Jiawei Chen, Yuan Feng, Yue Yang, Junchi Yan, Hongyuan Zha, Renqiu Xia",
      "journal": "arXiv",
      "snippet": "Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because \"black box\" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.",
      "link": "http://arxiv.org/abs/2601.05073v1",
      "published_date": "January 08, 2026",
      "published_date_sort": "2026-01-08",
      "citations": 0,
      "institutions": "Unknown"
    },
    {
      "title": "From Idea to Co-Creation: A Planner-Actor-Critic Framework for Agent Augmented 3D Modeling",
      "authors": "Jin Gao, Saichandu Juluri",
      "journal": "arXiv",
      "snippet": "We present a framework that extends the Actor-Critic architecture to creative 3D modeling through multi-agent self-reflection and human-in-the-loop supervision. While existing approaches rely on single-prompt agents that directly execute modeling commands via tools like Blender MCP, our approach introduces a Planner-Actor-Critic architecture. In this design, the Planner coordinates modeling steps, the Actor executes them, and the Critic provides iterative feedback, while human users act as supervisors and advisors throughout the process. Through systematic comparison between single-prompt modeling and our reflective multi-agent approach, we demonstrate improvements in geometric accuracy, aesthetic quality, and task completion rates across diverse 3D modeling scenarios. Our evaluation reveals that critic-guided reflection, combined with human supervisory input, reduces modeling errors and increases complexity and quality of the result compared to direct single-prompt execution. This work establishes that structured agent self-reflection, when augmented by human oversight and advisory guidance, produces higher-quality 3D models while maintaining efficient workflow integration through real-time Blender synchronization.",
      "link": "http://arxiv.org/abs/2601.05016v1",
      "published_date": "January 08, 2026",
      "published_date_sort": "2026-01-08",
      "citations": 0,
      "institutions": "Unknown"
    },
    {
      "title": "Reinforcement learning for machine learning engineering agents",
      "authors": "S Yang, J He-Yueya, P Liang - arXiv preprint arXiv:2509.01684, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Existing agents for solving tasks such as ML engineering rely on prompting powerful language models. As a result, these agents do not improve with more experience. In this …",
      "link": "https://arxiv.org/abs/2509.01684",
      "published_date": "September 2025",
      "published_date_sort": "2025-09-01",
      "citations": 1,
      "institutions": "Unknown"
    },
    {
      "title": "Bootstrapping task spaces for self-improvement",
      "authors": "M Jiang, A Lupu, Y Bachrach - arXiv preprint arXiv:2509.04575, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Progress in many task domains emerges from repeated revisions to previous solution attempts. Training agents that can reliably self-improve over such sequences at inference …",
      "link": "https://arxiv.org/abs/2509.04575",
      "published_date": "September 2025",
      "published_date_sort": "2025-09-01",
      "citations": 2,
      "institutions": "Unknown"
    },
    {
      "title": "An AI system to help scientists write expert-level empirical software",
      "authors": "E Aygün, A Belyaeva, G Comanici, M Coram… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "The cycle of scientific discovery is frequently bottlenecked by the slow, manual creation of software to support computational experiments. To address this, we present an AI system …",
      "link": "https://arxiv.org/abs/2509.06503",
      "published_date": "September 2025",
      "published_date_sort": "2025-09-01",
      "citations": 8,
      "institutions": "Unknown"
    },
    {
      "title": "Tuning llm-based code optimization via meta-prompting: An industrial perspective",
      "authors": "J Gong, R Giavrimis, P Brookes, V Voskanyan… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "There is a growing interest in leveraging multiple large language models (LLMs) for automated code optimization. However, industrial platforms deploying multiple LLMs face a …",
      "link": "https://arxiv.org/abs/2508.01443",
      "published_date": "August 2025",
      "published_date_sort": "2025-08-01",
      "citations": 4,
      "institutions": "Unknown"
    },
    {
      "title": "Kompeteai: Accelerated autonomous multi-agent system for end-to-end pipeline generation for machine learning problems",
      "authors": "S Kulibaba, A Dzhalilov, R Pakhomov… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive capabilities but face significant limitations such as constrained exploration strategies and a …",
      "link": "https://arxiv.org/abs/2508.10177",
      "published_date": "August 2025",
      "published_date_sort": "2025-08-01",
      "citations": 3,
      "institutions": "Unknown"
    },
    {
      "title": "How Far Are AI Scientists from Changing the World?",
      "authors": "Q Xie, Y Weng, M Zhu, F Shen, S Huang, Z Lin… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "The emergence of large language models (LLMs) is propelling automated scientific discovery to the next level, with LLM-based Artificial Intelligence (AI) Scientist systems now …",
      "link": "https://arxiv.org/abs/2507.23276",
      "published_date": "July 2025",
      "published_date_sort": "2025-07-01",
      "citations": 6,
      "institutions": "Unknown"
    },
    {
      "title": "Automind: Adaptive knowledgeable agent for automated data science",
      "authors": "Y Ou, Y Luo, J Zheng, L Wei, Z Yu, S Qiao… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Large Language Model (LLM) agents have shown great potential in addressing real-world data science problems. LLM-driven data science agents promise to automate the entire …",
      "link": "https://arxiv.org/abs/2506.10974",
      "published_date": "June 2025",
      "published_date_sort": "2025-06-01",
      "citations": 8,
      "institutions": "Unknown"
    },
    {
      "title": "A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications",
      "authors": "R Xu, J Peng - arXiv preprint arXiv:2506.12594, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "This survey examines the rapidly evolving field of Deep Research systems--AI-powered applications that automate complex research workflows through the integration of large …",
      "link": "https://arxiv.org/abs/2506.12594",
      "published_date": "June 2025",
      "published_date_sort": "2025-06-01",
      "citations": 35,
      "institutions": "Unknown"
    },
    {
      "title": "AI Scientists Fail Without Strong Implementation Capability",
      "authors": "M Zhu, Q Xie, Y Weng, J Wu, Z Lin, L Yang… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "The emergence of Artificial Intelligence (AI) Scientist represents a paradigm shift in scientific discovery, with large language models (LLMs) taking the lead as the primary executor in the …",
      "link": "https://arxiv.org/abs/2506.01372",
      "published_date": "June 2025",
      "published_date_sort": "2025-06-01",
      "citations": 9,
      "institutions": "Unknown"
    },
    {
      "title": "Mle-dojo: Interactive environments for empowering llm agents in machine learning engineering",
      "authors": "R Qiang, Y Zhuang, Y Li, R Zhang, C Li… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "We introduce MLE-Dojo, a Gym-style framework for systematically reinforcement learning, evaluating, and improving autonomous large language model (LLM) agents in iterative …",
      "link": "https://arxiv.org/abs/2505.07782",
      "published_date": "May 2025",
      "published_date_sort": "2025-05-01",
      "citations": 6,
      "institutions": "Unknown"
    },
    {
      "title": "Repomaster: Autonomous exploration and understanding of github repositories for complex task solving",
      "authors": "H Wang, Z Ni, S Zhang, S Lu, S Hu, Z He, C Hu… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "The ultimate goal of code agents is to solve complex tasks autonomously. Although large language models (LLMs) have made substantial progress in code generation, real-world …",
      "link": "https://arxiv.org/abs/2505.21577",
      "published_date": "May 2025",
      "published_date_sort": "2025-05-01",
      "citations": 8,
      "institutions": "Unknown"
    },
    {
      "title": "Mlzero: A multi-agent system for end-to-end machine learning automation",
      "authors": "H Fang, B Han, N Erickson, X Zhang, S Zhou… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Existing AutoML systems have advanced the automation of machine learning (ML); however, they still require substantial manual configuration and expert input, particularly …",
      "link": "https://arxiv.org/abs/2505.13941",
      "published_date": "May 2025",
      "published_date_sort": "2025-05-01",
      "citations": 3,
      "institutions": "Unknown"
    },
    {
      "title": "CodePDE: An Inference Framework for LLM-driven PDE Solver Generation",
      "authors": "S Li, T Marwah, J Shen, W Sun, A Risteski… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Partial differential equations (PDEs) are fundamental to modeling physical systems, yet solving them remains a complex challenge. Traditional numerical solvers rely on expert …",
      "link": "https://arxiv.org/abs/2505.08783",
      "published_date": "May 2025",
      "published_date_sort": "2025-05-01",
      "citations": 7,
      "institutions": "Unknown"
    },
    {
      "title": "From automation to autonomy: A survey on large language models in scientific discovery",
      "authors": "T Zheng, Z Deng, HT Tsang, W Wang, J Bai… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Large Language Models (LLMs) are catalyzing a paradigm shift in scientific discovery, evolving from task-specific automation tools into increasingly autonomous agents and …",
      "link": "https://arxiv.org/abs/2505.13259",
      "published_date": "May 2025",
      "published_date_sort": "2025-05-01",
      "citations": 29,
      "institutions": "Unknown"
    },
    {
      "title": "IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis",
      "authors": "H Li, H Liu, T Zhu, T Guo, Z Zheng, X Deng… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Large Language Models (LLMs) show promise as data analysis agents, but existing benchmarks overlook the iterative nature of the field, where experts' decisions evolve with …",
      "link": "https://arxiv.org/abs/2505.18223",
      "published_date": "May 2025",
      "published_date_sort": "2025-05-01",
      "citations": 2,
      "institutions": "Unknown"
    },
    {
      "title": "Co-bench: Benchmarking language model agents in algorithm search for combinatorial optimization",
      "authors": "W Sun, S Feng, S Li, Y Yang - arXiv preprint arXiv:2504.04310, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Although LLM-based agents have attracted significant attention in domains such as software engineering and machine learning research, their role in advancing combinatorial …",
      "link": "https://arxiv.org/abs/2504.04310",
      "published_date": "April 2025",
      "published_date_sort": "2025-04-01",
      "citations": 17,
      "institutions": "Unknown"
    },
    {
      "title": "Measuring ai ability to complete long tasks",
      "authors": "T Kwa, B West, J Becker, A Deng, K Garcia… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Despite rapid progress on AI benchmarks, the real-world meaning of benchmark performance remains unclear. To quantify the capabilities of AI systems in terms of human …",
      "link": "https://arxiv.org/abs/2503.14499",
      "published_date": "March 2025",
      "published_date_sort": "2025-03-01",
      "citations": 65,
      "institutions": "Unknown"
    },
    {
      "title": "An agentic framework for autonomous metamaterial modeling and inverse design",
      "authors": "D Lu, JM Malof, WJ Padilla - ACS Photonics, 2025 - ACS Publications",
      "journal": "Google Scholar Result",
      "snippet": "The evolution from large language models to agentic systems has created a new Frontier of scientific discovery, enabling the automation of complex research tasks that have …",
      "link": "https://pubs.acs.org/doi/abs/10.1021/acsphotonics.5c01514",
      "published_date": "2025",
      "published_date_sort": "2025-01-01",
      "citations": 6,
      "institutions": "Unknown"
    },
    {
      "title": "AIRepr: An Analyst-Inspector Framework for Evaluating Reproducibility of LLMs in Data Science",
      "authors": "Q Zeng, C Jin, X Wang, Y Zheng… - Findings of the Association …, 2025 - aclanthology.org",
      "journal": "Google Scholar Result",
      "snippet": "Large language models (LLMs) are increasingly used to automate data analysis through executable code generation. Yet, data science tasks often admit multiple statistically valid …",
      "link": "https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.539.pdf",
      "published_date": "2025",
      "published_date_sort": "2025-01-01",
      "citations": 1,
      "institutions": "Unknown"
    },
    {
      "title": "Large language models for constructing and optimizing machine learning workflows: A survey",
      "authors": "Y Gu, H You, J Cao, M Yu, H Fan, S Qian - ACM Transactions on …, 2024 - dl.acm.org",
      "journal": "Google Scholar Result",
      "snippet": "Machine Learning (ML) workflows—spanning data preprocessing and feature engineering, model selection and hyperparameter optimization, and workflow evaluation—are …",
      "link": "https://dl.acm.org/doi/abs/10.1145/3773084",
      "published_date": "2024",
      "published_date_sort": "2024-01-01",
      "citations": 13,
      "institutions": "Unknown"
    }
  ]
}