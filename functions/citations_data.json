{
  "last_updated": "2025-12-04 00:11:07 UTC",
  "target_paper": "https://www.arxiv.org/abs/2502.13138",
  "arxiv_id": "2502.13138",
  "total_citations": 23,
  "h_index": 7,
  "recent_citations": 3,
  "avg_citations_per_month": "0.96",
  "timeline": [
    {
      "date": "2024-01-01",
      "citations": 1
    },
    {
      "date": "2025-01-01",
      "citations": 3
    },
    {
      "date": "2025-03-01",
      "citations": 4
    },
    {
      "date": "2025-04-01",
      "citations": 5
    },
    {
      "date": "2025-05-01",
      "citations": 11
    },
    {
      "date": "2025-06-01",
      "citations": 14
    },
    {
      "date": "2025-07-01",
      "citations": 15
    },
    {
      "date": "2025-08-01",
      "citations": 17
    },
    {
      "date": "2025-09-01",
      "citations": 19
    },
    {
      "date": "2025-10-01",
      "citations": 20
    },
    {
      "date": "2025-12-01",
      "citations": 23
    }
  ],
  "papers": [
    {
      "title": "Model-Based Diagnosis with Multiple Observations: A Unified Approach for C Software and Boolean Circuits",
      "authors": "Pedro Orvalho, Marta Kwiatkowska, Mikoláš Janota, Vasco Manquinho",
      "journal": "arXiv",
      "snippet": "Debugging is one of the most time-consuming and expensive tasks in software development and circuit design. Several formula-based fault localisation (FBFL) methods have been proposed, but they fail to guarantee a set of diagnoses across all failing tests or may produce redundant diagnoses that are not subset-minimal, particularly for programs/circuits with multiple faults.\n  This paper introduces CFaults, a novel fault localisation tool for C software and Boolean circuits with multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple observations and aggregates all failing test cases into a unified Maximum Satisfiability (MaxSAT) formula. Consequently, our method guarantees consistency across observations and simplifies the fault localisation procedure. Experimental results on three benchmark sets, two of C programs, TCAS and C-Pack-IPAs, and one of Boolean circuits, ISCAS85, show that CFaults is faster at localising faults in C software than other FBFL approaches such as BugAssist, SNIPER, and HSD. On the ISCAS85 benchmark, CFaults is generally slower than HSD; however, it localises faults in only 6% fewer circuits, demonstrating that it remains competitive in this domain. Furthermore, CFaults produces only subset-minimal diagnoses of faulty statements, whereas the other approaches tend to enumerate redundant diagnoses (e.g., BugAssist and SNIPER).",
      "link": "http://arxiv.org/abs/2512.02898v1",
      "published_date": "December 02, 2025",
      "published_date_sort": "2025-12-02",
      "citations": 0,
      "institutions": "Unknown"
    },
    {
      "title": "Are Detectors Fair to Indian IP-AIGC? A Cross-Generator Study",
      "authors": "Vishal Dubey, Pallavi Tyagi",
      "journal": "arXiv",
      "snippet": "Modern image editors can produce identity-preserving AIGC (IP-AIGC), where the same person appears with new attire, background, or lighting. The robustness and fairness of current detectors in this regime remain unclear, especially for under-represented populations. We present what we believe is the first systematic study of IP-AIGC detection for Indian and South-Asian faces, quantifying cross-generator generalization and intra-population performance. We assemble Indian-focused training splits from FairFD and HAV-DF, and construct two held-out IP-AIGC test sets (HIDF-img-ip-genai and HIDF-vid-ip-genai) using commercial web-UI generators (Gemini and ChatGPT) with identity-preserving prompts. We evaluate two state-of-the-art detectors (AIDE and Effort) under pretrained (PT) and fine-tuned (FT) regimes and report AUC, AP, EER, and accuracy. Fine-tuning yields strong in-domain gains (for example, Effort AUC 0.739 to 0.944 on HAV-DF-test; AIDE EER 0.484 to 0.259), but consistently degrades performance on held-out IP-AIGC for Indian cohorts (for example, AIDE AUC 0.923 to 0.563 on HIDF-img-ip-genai; Effort 0.740 to 0.533), which indicates overfitting to training-generator cues. On non-IP HIDF images, PT performance remains high, which suggests a specific brittleness to identity-preserving edits rather than a generic distribution shift. Our study establishes IP-AIGC-Indian as a challenging and practically relevant scenario and motivates representation-preserving adaptation and India-aware benchmark curation to close generalization gaps in AIGC detection.",
      "link": "http://arxiv.org/abs/2512.02850v1",
      "published_date": "December 02, 2025",
      "published_date_sort": "2025-12-02",
      "citations": 0,
      "institutions": "Unknown"
    },
    {
      "title": "From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?",
      "authors": "Dawei Li, Abdullah Alnaibari, Arslan Bisharat, Manny Sandoval, Deborah Hall, Yasin Silva, Huan Liu",
      "journal": "arXiv",
      "snippet": "The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts. Our framework decomposes mediation into two subtasks: judgment, where an LLM evaluates the fairness and emotional dynamics of a conversation, and steering, where it generates empathetic, de-escalatory messages to guide participants toward resolution. To assess mediation quality, we construct a large Reddit-based dataset and propose a multi-stage evaluation pipeline combining principle-based scoring, user simulation, and human comparison. Experiments show that API-based models outperform open-source counterparts in both reasoning and intervention alignment when doing mediation. Our findings highlight both the promise and limitations of current LLMs as emerging agents for online social mediation.",
      "link": "http://arxiv.org/abs/2512.03005v1",
      "published_date": "December 02, 2025",
      "published_date_sort": "2025-12-02",
      "citations": 0,
      "institutions": "Unknown"
    },
    {
      "title": "AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents",
      "authors": "S Du, X Yan, D Jiang, J Yuan, Y Hu, X Li, L He… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Large language models (LLMs) have shown impressive performance in general programming tasks. However, in Machine Learning Engineering (MLE) scenarios such as …",
      "link": "https://arxiv.org/abs/2510.08511",
      "published_date": "October 2025",
      "published_date_sort": "2025-10-01",
      "citations": 1,
      "institutions": "Unknown"
    },
    {
      "title": "Reinforcement learning for machine learning engineering agents",
      "authors": "S Yang, J He-Yueya, P Liang - arXiv preprint arXiv:2509.01684, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Existing agents for solving tasks such as ML engineering rely on prompting powerful language models. As a result, these agents do not improve with more experience. In this …",
      "link": "https://arxiv.org/abs/2509.01684",
      "published_date": "September 2025",
      "published_date_sort": "2025-09-01",
      "citations": 2,
      "institutions": "Unknown"
    },
    {
      "title": "An AI system to help scientists write expert-level empirical software",
      "authors": "E Aygün, A Belyaeva, G Comanici, M Coram… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "The cycle of scientific discovery is frequently bottlenecked by the slow, manual creation of software to support computational experiments. To address this, we present an AI system …",
      "link": "https://arxiv.org/abs/2509.06503",
      "published_date": "September 2025",
      "published_date_sort": "2025-09-01",
      "citations": 6,
      "institutions": "Unknown"
    },
    {
      "title": "KompeteAI: Accelerated autonomous multi-agent system for end-to-end pipeline generation for machine learning problems",
      "authors": "S Kulibaba, A Dzhalilov, R Pakhomov… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive capabilities but face significant limitations such as constrained exploration strategies and a …",
      "link": "https://arxiv.org/abs/2508.10177",
      "published_date": "August 2025",
      "published_date_sort": "2025-08-01",
      "citations": 3,
      "institutions": "Unknown"
    },
    {
      "title": "Tuning llm-based code optimization via meta-prompting: An industrial perspective",
      "authors": "J Gong, R Giavrimis, P Brookes, V Voskanyan… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "There is a growing interest in leveraging multiple large language models (LLMs) for automated code optimization. However, industrial platforms deploying multiple LLMs face a …",
      "link": "https://arxiv.org/abs/2508.01443",
      "published_date": "August 2025",
      "published_date_sort": "2025-08-01",
      "citations": 2,
      "institutions": "Unknown"
    },
    {
      "title": "How Far Are AI Scientists from Changing the World?",
      "authors": "Q Xie, Y Weng, M Zhu, F Shen, S Huang, Z Lin… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "The emergence of large language models (LLMs) is propelling automated scientific discovery to the next level, with LLM-based Artificial Intelligence (AI) Scientist systems now …",
      "link": "https://arxiv.org/abs/2507.23276",
      "published_date": "July 2025",
      "published_date_sort": "2025-07-01",
      "citations": 7,
      "institutions": "Unknown"
    },
    {
      "title": "A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications",
      "authors": "R Xu, J Peng - arXiv preprint arXiv:2506.12594, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "This survey examines the rapidly evolving field of Deep Research systems--AI-powered applications that automate complex research workflows through the integration of large …",
      "link": "https://arxiv.org/abs/2506.12594",
      "published_date": "June 2025",
      "published_date_sort": "2025-06-01",
      "citations": 26,
      "institutions": "Unknown"
    },
    {
      "title": "Automind: Adaptive knowledgeable agent for automated data science",
      "authors": "Y Ou, Y Luo, J Zheng, L Wei, Z Yu, S Qiao… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Large Language Model (LLM) agents have shown great potential in addressing real-world data science problems. LLM-driven data science agents promise to automate the entire …",
      "link": "https://arxiv.org/abs/2506.10974",
      "published_date": "June 2025",
      "published_date_sort": "2025-06-01",
      "citations": 5,
      "institutions": "Unknown"
    },
    {
      "title": "AI Scientists Fail Without Strong Implementation Capability",
      "authors": "M Zhu, Q Xie, Y Weng, J Wu, Z Lin, L Yang… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "The emergence of Artificial Intelligence (AI) Scientist represents a paradigm shift in scientific discovery, with large language models (LLMs) taking the lead as the primary executor in the …",
      "link": "https://arxiv.org/abs/2506.01372",
      "published_date": "June 2025",
      "published_date_sort": "2025-06-01",
      "citations": 8,
      "institutions": "Unknown"
    },
    {
      "title": "From automation to autonomy: A survey on large language models in scientific discovery",
      "authors": "T Zheng, Z Deng, HT Tsang, W Wang, J Bai… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Large Language Models (LLMs) are catalyzing a paradigm shift in scientific discovery, evolving from task-specific automation tools into increasingly autonomous agents and …",
      "link": "https://arxiv.org/abs/2505.13259",
      "published_date": "May 2025",
      "published_date_sort": "2025-05-01",
      "citations": 24,
      "institutions": "Unknown"
    },
    {
      "title": "CodePDE: An Inference Framework for LLM-driven PDE Solver Generation",
      "authors": "S Li, T Marwah, J Shen, W Sun, A Risteski… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Partial differential equations (PDEs) are fundamental to modeling physical systems, yet solving them remains a complex challenge. Traditional numerical solvers rely on expert …",
      "link": "https://arxiv.org/abs/2505.08783",
      "published_date": "May 2025",
      "published_date_sort": "2025-05-01",
      "citations": 6,
      "institutions": "Unknown"
    },
    {
      "title": "Mlzero: A multi-agent system for end-to-end machine learning automation",
      "authors": "H Fang, B Han, N Erickson, X Zhang, S Zhou… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Existing AutoML systems have advanced the automation of machine learning (ML); however, they still require substantial manual configuration and expert input, particularly …",
      "link": "https://arxiv.org/abs/2505.13941",
      "published_date": "May 2025",
      "published_date_sort": "2025-05-01",
      "citations": 4,
      "institutions": "Unknown"
    },
    {
      "title": "IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis",
      "authors": "H Li, H Liu, T Zhu, T Guo, Z Zheng, X Deng… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Large Language Models (LLMs) show promise as data analysis agents, but existing benchmarks overlook the iterative nature of the field, where experts' decisions evolve with …",
      "link": "https://arxiv.org/abs/2505.18223",
      "published_date": "May 2025",
      "published_date_sort": "2025-05-01",
      "citations": 2,
      "institutions": "Unknown"
    },
    {
      "title": "Repomaster: Autonomous exploration and understanding of github repositories for complex task solving",
      "authors": "H Wang, Z Ni, S Zhang, S Lu, S Hu, Z He, C Hu… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "The ultimate goal of code agents is to solve complex tasks autonomously. Although large language models (LLMs) have made substantial progress in code generation, real-world …",
      "link": "https://arxiv.org/abs/2505.21577",
      "published_date": "May 2025",
      "published_date_sort": "2025-05-01",
      "citations": 6,
      "institutions": "Unknown"
    },
    {
      "title": "Mle-dojo: Interactive environments for empowering llm agents in machine learning engineering",
      "authors": "R Qiang, Y Zhuang, Y Li, R Zhang, C Li… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "We introduce MLE-Dojo, a Gym-style framework for systematically reinforcement learning, evaluating, and improving autonomous large language model (LLM) agents in iterative …",
      "link": "https://arxiv.org/abs/2505.07782",
      "published_date": "May 2025",
      "published_date_sort": "2025-05-01",
      "citations": 6,
      "institutions": "Unknown"
    },
    {
      "title": "Co-bench: Benchmarking language model agents in algorithm search for combinatorial optimization",
      "authors": "W Sun, S Feng, S Li, Y Yang - arXiv preprint arXiv:2504.04310, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Although LLM-based agents have attracted significant attention in domains such as software engineering and machine learning research, their role in advancing combinatorial …",
      "link": "https://arxiv.org/abs/2504.04310",
      "published_date": "April 2025",
      "published_date_sort": "2025-04-01",
      "citations": 17,
      "institutions": "Unknown"
    },
    {
      "title": "Measuring ai ability to complete long tasks",
      "authors": "T Kwa, B West, J Becker, A Deng, K Garcia… - arXiv preprint arXiv …, 2025 - arxiv.org",
      "journal": "Google Scholar Result",
      "snippet": "Despite rapid progress on AI benchmarks, the real-world meaning of benchmark performance remains unclear. To quantify the capabilities of AI systems in terms of human …",
      "link": "https://arxiv.org/abs/2503.14499",
      "published_date": "March 2025",
      "published_date_sort": "2025-03-01",
      "citations": 58,
      "institutions": "Unknown"
    },
    {
      "title": "An agentic framework for autonomous metamaterial modeling and inverse design",
      "authors": "D Lu, JM Malof, WJ Padilla - ACS Photonics, 2025 - ACS Publications",
      "journal": "Google Scholar Result",
      "snippet": "The evolution from large language models to agentic systems has created a new Frontier of scientific discovery, enabling the automation of complex research tasks that have …",
      "link": "https://pubs.acs.org/doi/abs/10.1021/acsphotonics.5c01514",
      "published_date": "2025",
      "published_date_sort": "2025-01-01",
      "citations": 2,
      "institutions": "Unknown"
    },
    {
      "title": "AIRepr: An Analyst-Inspector Framework for Evaluating Reproducibility of LLMs in Data Science",
      "authors": "Q Zeng, C Jin, X Wang, Y Zheng… - Findings of the Association …, 2025 - aclanthology.org",
      "journal": "Google Scholar Result",
      "snippet": "Large language models (LLMs) are increasingly used to automate data analysis through executable code generation. Yet, data science tasks often admit multiple statistically valid …",
      "link": "https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.539.pdf",
      "published_date": "2025",
      "published_date_sort": "2025-01-01",
      "citations": 1,
      "institutions": "Unknown"
    },
    {
      "title": "Large language models for constructing and optimizing machine learning workflows: A survey",
      "authors": "Y Gu, H You, J Cao, M Yu, H Fan, S Qian - ACM Transactions on …, 2024 - dl.acm.org",
      "journal": "Google Scholar Result",
      "snippet": "Machine Learning (ML) workflows—spanning data preprocessing and feature engineering, model selection and hyperparameter optimization, and workflow evaluation—are …",
      "link": "https://dl.acm.org/doi/abs/10.1145/3773084",
      "published_date": "2024",
      "published_date_sort": "2024-01-01",
      "citations": 13,
      "institutions": "Unknown"
    }
  ]
}